---
phase: 02-query-routing-engine
plan: 02
type: execute
wave: 2
depends_on: ["02-01"]
files_modified:
  - utils/query_router.py
  - tests/test_query_router.py
  - app.py
autonomous: true

must_haves:
  truths:
    - "Ambiguous queries (no keyword match) trigger LLM classification"
    - "LLM classifies intent into one of 5 categories (RANKING/SECTOR/TIMESERIES/LATEST/GENERAL)"
    - "LLM failures gracefully fall back to tasi_financials"
    - "Confidence score indicates routing certainty (1.0 keyword, 0.8 LLM, 0.5 fallback)"
    - "UI shows confidence level for user transparency"
  artifacts:
    - path: "utils/query_router.py"
      provides: "LLM intent classification"
      contains: "_llm_classify"
    - path: "tests/test_query_router.py"
      provides: "LLM classification tests"
      contains: "test_llm_"
  key_links:
    - from: "utils/query_router.py"
      to: "pandasai.config.llm"
      via: "LLM chat call"
      pattern: "pai\\.config\\.llm|llm\\.chat"
    - from: "app.py"
      to: "utils/query_router.py"
      via: "router.route() with confidence"
      pattern: "confidence"
---

<objective>
Implement LLM-based intent classification for ambiguous queries with confidence scoring.

Purpose: When keyword matching fails, use LLM to classify query intent before falling back to full dataset. This completes ROUTE-02 (LLM classification) and adds transparency via confidence scores.

Output: QueryRouter with LLM fallback capability and confidence scoring, integrated into app.py.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-query-routing-engine/02-RESEARCH.md
@.planning/phases/02-query-routing-engine/02-01-SUMMARY.md

@utils/query_router.py
@utils/llm_config.py
@app.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement LLM intent classification in QueryRouter</name>
  <files>utils/query_router.py</files>
  <action>
Add LLM-based intent classification for ambiguous queries.

1. **Update route() method signature** to include confidence:
   ```python
   def route(self, query: str) -> Tuple[str, str, dict, float]:
       """Route query to optimal view.

       Returns:
           (view_name, reason, entities, confidence)
           confidence: 1.0 for keyword match, 0.8 for LLM, 0.5 for fallback
       """
   ```

2. **Update route() logic** to call LLM for ambiguous queries:
   ```python
   # Step 1: Extract entities
   entities = self._extract_entities(query) if self.ticker_index is not None else {}

   # Step 2: Keyword matching (existing logic)
   view, reason = self._keyword_route(query)
   if view != "tasi_financials":
       return view, reason, entities, 1.0  # High confidence

   # Step 3: LLM classification (if enabled and ambiguous)
   if self.llm_enabled:
       view, reason = self._llm_classify(query, entities)
       if view != "tasi_financials":
           return view, reason, entities, 0.8  # LLM confidence

   # Step 4: Fallback
   return "tasi_financials", "General query - using full dataset", entities, 0.5
   ```

3. **Extract keyword routing to _keyword_route()** private method (refactor existing code).

4. **Add _llm_classify() method** using classification prompt from research:
   ```python
   def _llm_classify(self, query: str, entities: dict) -> Tuple[str, str]:
       """Use LLM to classify ambiguous query intent."""
       prompt = f'''Classify this financial query into ONE category:

   Query: "{query}"

   Categories (choose ONE):
   - RANKING: Comparing companies, top/bottom N, best/worst performers
   - SECTOR: Sector-level analysis, industry comparisons, sector averages
   - TIMESERIES: Trends over time, growth rates, historical analysis, YoY changes
   - LATEST: Current metrics, most recent data, specific company's latest numbers
   - GENERAL: Complex multi-dimensional queries, unclear intent

   Detected entities: {entities}

   Respond in this exact format:
   CATEGORY|reason

   Example: TIMESERIES|Query asks about revenue change over years'''

       try:
           import pandasai as pai
           response = pai.config.llm.chat(prompt)

           # Parse response (CATEGORY|reason format)
           if '|' in response:
               category, reason = response.split('|', 1)
               category = category.strip().upper()
           else:
               category = response.strip().upper()
               reason = "LLM classification"

           # Map category to view
           category_to_view = {
               'RANKING': 'top_bottom_performers',
               'SECTOR': 'sector_benchmarks_latest',
               'TIMESERIES': 'company_annual_timeseries',
               'LATEST': 'latest_financials',
               'GENERAL': 'tasi_financials'
           }

           view = category_to_view.get(category, 'tasi_financials')
           return view, f"LLM: {reason.strip()}"

       except Exception as e:
           logger.warning(f"LLM classification failed: {e}")
           return 'tasi_financials', 'Fallback: LLM classification failed'
   ```

5. **Update route_query() function** for backward compatibility:
   - Return only (view_name, reason) to maintain existing interface
   - Internally use QueryRouter with llm_enabled=False (keyword-only)

Avoid: Don't call LLM for queries that match keywords - LLM is only for ambiguous queries. Keep LLM call lightweight (single prompt, no retries).
  </action>
  <verify>
Run `python -c "from utils.query_router import QueryRouter; r = QueryRouter(llm_enabled=True); print(r.route('analyze SABIC performance'))"` - should return 4-tuple with confidence.
  </verify>
  <done>
QueryRouter has _llm_classify() method, route() returns 4-tuple with confidence, LLM only called for ambiguous queries.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add LLM classification tests</name>
  <files>tests/test_query_router.py</files>
  <action>
Extend test file with LLM classification tests using mocks.

1. **Mock PandasAI LLM** for testing:
   ```python
   @pytest.fixture
   def mock_llm():
       """Mock PandasAI LLM for testing."""
       with patch('pandasai.config.llm') as mock:
           yield mock
   ```

2. **Test LLM classification scenarios:**
   - test_llm_classify_ranking: mock returns "RANKING|comparing companies" -> top_bottom_performers
   - test_llm_classify_sector: mock returns "SECTOR|industry analysis" -> sector_benchmarks_latest
   - test_llm_classify_timeseries: mock returns "TIMESERIES|historical trend" -> company_annual_timeseries
   - test_llm_classify_latest: mock returns "LATEST|current data" -> latest_financials
   - test_llm_classify_general: mock returns "GENERAL|complex query" -> tasi_financials

3. **Test LLM failure handling:**
   - test_llm_failure_fallback: mock raises Exception -> fallback to tasi_financials with 0.5 confidence
   - test_llm_timeout: mock raises TimeoutError -> graceful fallback

4. **Test confidence scoring:**
   - test_confidence_keyword_match: keyword query returns 1.0 confidence
   - test_confidence_llm_match: LLM-routed query returns 0.8 confidence
   - test_confidence_fallback: no match returns 0.5 confidence

5. **Test LLM not called for keyword matches:**
   - test_llm_not_called_for_keywords: verify LLM mock not called when keywords match

6. **Test backward compatibility:**
   - test_route_query_returns_tuple_of_two: route_query() returns (str, str) not 4-tuple

Use pytest-mock or unittest.mock.patch for mocking.
  </action>
  <verify>
Run `pytest tests/test_query_router.py -v -k "llm"` - all LLM tests pass.
Run `pytest tests/test_query_router.py -v` - all tests pass including existing ones.
  </verify>
  <done>
Test file has 10+ new tests covering LLM classification, failure handling, confidence scoring, and backward compatibility. All tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 3: Update app.py to show confidence and enable LLM routing</name>
  <files>app.py</files>
  <action>
Update app.py to use enhanced router with LLM fallback and display confidence.

1. **Update router instantiation** to enable LLM:
   ```python
   router = QueryRouter(ticker_index=data['ticker_index'], llm_enabled=True)
   ```

2. **Update route() call** to handle 4-tuple return:
   ```python
   view_name, route_reason, entities, confidence = router.route(prompt)
   ```

3. **Add confidence display** with color coding:
   ```python
   # Confidence label with color
   if confidence >= 0.9:
       confidence_label = "HIGH"
       confidence_color = "green"
   elif confidence >= 0.7:
       confidence_label = "MEDIUM"
       confidence_color = "orange"
   else:
       confidence_label = "LOW"
       confidence_color = "red"

   # Build routing caption
   entity_info = ""
   if entities.get('tickers'):
       entity_info = f" | Detected: {', '.join(entities['tickers'])}"
   elif entities.get('companies'):
       entity_info = f" | Detected: {', '.join(entities['companies'][:2])}"

   st.caption(f"Using: {view_name} (:{confidence_color}[{confidence_label}]){entity_info}")
   ```

4. **Add route reason to debug/log** (optional, for transparency):
   ```python
   logger.info(f"Routed '{prompt[:50]}...' to {view_name}: {route_reason}")
   ```

Avoid: Don't add complex UI elements. Keep caption simple. Don't expose raw confidence number to users (use labels).
  </action>
  <verify>
1. Run `streamlit run app.py` and query "top 10 companies" - should show "Using: top_bottom_performers (:green[HIGH])"
2. Run `streamlit run app.py` and query "analyze SABIC performance" - should show "Using: ... (:orange[MEDIUM])" (LLM routed)
3. Run `streamlit run app.py` and query "show all data" - should show "Using: tasi_financials (:red[LOW])"
  </verify>
  <done>
app.py uses QueryRouter with LLM enabled, displays confidence level with color coding, logs routing decisions.
  </done>
</task>

</tasks>

<verification>
1. `pytest tests/test_query_router.py -v` - all tests pass (25+ tests)
2. Query "top 10" shows HIGH confidence (keyword match)
3. Query "how is SABIC doing" shows MEDIUM confidence (LLM classification)
4. Query "random gibberish" shows LOW confidence (fallback)
5. LLM errors don't crash the app (graceful fallback)
</verification>

<success_criteria>
- LLM classification implemented for ambiguous queries only (not for keyword matches)
- Confidence scoring: 1.0 keyword, 0.8 LLM, 0.5 fallback
- LLM failures gracefully fall back to tasi_financials
- UI shows confidence level with color coding (green/orange/red)
- All tests pass including new LLM tests
- Phase 2 success criteria met:
  1. Query with "latest" routes to latest_financials (keyword)
  2. Query with company/ticker detected via entity extraction
  3. Ambiguous queries trigger LLM classification
  4. Unknown queries fall back to tasi_financials
  5. PandasAI operates on routed DataFrame
</success_criteria>

<output>
After completion, create `.planning/phases/02-query-routing-engine/02-02-SUMMARY.md`
</output>
